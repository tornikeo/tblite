{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff2136c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "option = 'H100_80GB_HBM3'\n",
    "!mkdir -p notes/capture/{option}\n",
    "!mkdir -p notes/data/{option}\n",
    "!meson test -C build/ hamiltonian-batch --verbose -t 0 > notes/capture/{option}/batchgpu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd98dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu_time</th>\n",
       "      <th>gpu_gb_in</th>\n",
       "      <th>gpu_gb_out</th>\n",
       "      <th>gpu_gb_total</th>\n",
       "      <th>gpu_between_atoms</th>\n",
       "      <th>gpu_in_atoms</th>\n",
       "      <th>gpu_time</th>\n",
       "      <th>gpu_transfer_time</th>\n",
       "      <th>gpu_walltime</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.504586</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>5.476960</td>\n",
       "      <td>0.385376</td>\n",
       "      <td>5.862336</td>\n",
       "      <td>1.426080</td>\n",
       "      <td>1072.3413107916713</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.719504</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.317312</td>\n",
       "      <td>0.689280</td>\n",
       "      <td>1.323904</td>\n",
       "      <td>2.037120</td>\n",
       "      <td>5.4114935919642448</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.255725</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.129616</td>\n",
       "      <td>0.248672</td>\n",
       "      <td>0.767136</td>\n",
       "      <td>1.502592</td>\n",
       "      <td>2.8033191338181496</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.731307</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.085680</td>\n",
       "      <td>0.254144</td>\n",
       "      <td>0.939584</td>\n",
       "      <td>1.485504</td>\n",
       "      <td>2.9148990288376808</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.633493</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.069880</td>\n",
       "      <td>0.259744</td>\n",
       "      <td>1.377824</td>\n",
       "      <td>1.561120</td>\n",
       "      <td>3.4534763544797897</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78.350078</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.063966</td>\n",
       "      <td>0.320800</td>\n",
       "      <td>2.367712</td>\n",
       "      <td>1.943936</td>\n",
       "      <td>4.7418596222996712</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.886853</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.059726</td>\n",
       "      <td>0.251360</td>\n",
       "      <td>4.073792</td>\n",
       "      <td>1.744800</td>\n",
       "      <td>6.1980243772268295</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80.232245</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.061810</td>\n",
       "      <td>0.262048</td>\n",
       "      <td>8.173728</td>\n",
       "      <td>1.622336</td>\n",
       "      <td>10.174023918807507</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.536687</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.062930</td>\n",
       "      <td>0.246944</td>\n",
       "      <td>16.356960</td>\n",
       "      <td>1.403744</td>\n",
       "      <td>18.109570257365704</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>58.959151</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.258656</td>\n",
       "      <td>33.722561</td>\n",
       "      <td>1.604832</td>\n",
       "      <td>35.688198171555996</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>52.157986</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.065495</td>\n",
       "      <td>0.274144</td>\n",
       "      <td>67.340736</td>\n",
       "      <td>1.525600</td>\n",
       "      <td>69.247191771864891</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22.990286</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.067269</td>\n",
       "      <td>0.264160</td>\n",
       "      <td>138.030212</td>\n",
       "      <td>1.598624</td>\n",
       "      <td>140.00959787517786</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.995061</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.067658</td>\n",
       "      <td>0.256736</td>\n",
       "      <td>277.384521</td>\n",
       "      <td>1.519232</td>\n",
       "      <td>279.24272231757641</td>\n",
       "      <td>4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22.684675</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.067859</td>\n",
       "      <td>0.390592</td>\n",
       "      <td>556.292542</td>\n",
       "      <td>1.594368</td>\n",
       "      <td>558.33259504288435</td>\n",
       "      <td>8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28.698579</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.068069</td>\n",
       "      <td>0.460928</td>\n",
       "      <td>1115.710815</td>\n",
       "      <td>1.974048</td>\n",
       "      <td>1118.2211814448237</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34.378525</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.068891</td>\n",
       "      <td>0.386912</td>\n",
       "      <td>2257.811768</td>\n",
       "      <td>1.979936</td>\n",
       "      <td>2260.3351343423128</td>\n",
       "      <td>32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29.717544</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.068902</td>\n",
       "      <td>0.587424</td>\n",
       "      <td>4516.165039</td>\n",
       "      <td>1.874432</td>\n",
       "      <td>4518.6304813250899</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cpu_time  gpu_gb_in  gpu_gb_out  gpu_gb_total  gpu_between_atoms  \\\n",
       "0   23.504586    0.00106    0.001046      0.002105           5.476960   \n",
       "1   29.719504    0.00106    0.001046      0.002105           0.317312   \n",
       "2   47.255725    0.00106    0.001046      0.002105           0.129616   \n",
       "3   21.731307    0.00106    0.001046      0.002105           0.085680   \n",
       "4   76.633493    0.00106    0.001046      0.002105           0.069880   \n",
       "5   78.350078    0.00106    0.001046      0.002105           0.063966   \n",
       "6   20.886853    0.00106    0.001046      0.002105           0.059726   \n",
       "7   80.232245    0.00106    0.001046      0.002105           0.061810   \n",
       "8   24.536687    0.00106    0.001046      0.002105           0.062930   \n",
       "9   58.959151    0.00106    0.001046      0.002105           0.065359   \n",
       "10  52.157986    0.00106    0.001046      0.002105           0.065495   \n",
       "11  22.990286    0.00106    0.001046      0.002105           0.067269   \n",
       "12  18.995061    0.00106    0.001046      0.002105           0.067658   \n",
       "13  22.684675    0.00106    0.001046      0.002105           0.067859   \n",
       "14  28.698579    0.00106    0.001046      0.002105           0.068069   \n",
       "15  34.378525    0.00106    0.001046      0.002105           0.068891   \n",
       "16  29.717544    0.00106    0.001046      0.002105           0.068902   \n",
       "\n",
       "    gpu_in_atoms     gpu_time  gpu_transfer_time        gpu_walltime  \\\n",
       "0       0.385376     5.862336           1.426080  1072.3413107916713   \n",
       "1       0.689280     1.323904           2.037120  5.4114935919642448   \n",
       "2       0.248672     0.767136           1.502592  2.8033191338181496   \n",
       "3       0.254144     0.939584           1.485504  2.9148990288376808   \n",
       "4       0.259744     1.377824           1.561120  3.4534763544797897   \n",
       "5       0.320800     2.367712           1.943936  4.7418596222996712   \n",
       "6       0.251360     4.073792           1.744800  6.1980243772268295   \n",
       "7       0.262048     8.173728           1.622336  10.174023918807507   \n",
       "8       0.246944    16.356960           1.403744  18.109570257365704   \n",
       "9       0.258656    33.722561           1.604832  35.688198171555996   \n",
       "10      0.274144    67.340736           1.525600  69.247191771864891   \n",
       "11      0.264160   138.030212           1.598624  140.00959787517786   \n",
       "12      0.256736   277.384521           1.519232  279.24272231757641   \n",
       "13      0.390592   556.292542           1.594368  558.33259504288435   \n",
       "14      0.460928  1115.710815           1.974048  1118.2211814448237   \n",
       "15      0.386912  2257.811768           1.979936  2260.3351343423128   \n",
       "16      0.587424  4516.165039           1.874432  4518.6304813250899   \n",
       "\n",
       "    batch_size  \n",
       "0            1  \n",
       "1            2  \n",
       "2            4  \n",
       "3            8  \n",
       "4           16  \n",
       "5           32  \n",
       "6           64  \n",
       "7          128  \n",
       "8          256  \n",
       "9          512  \n",
       "10        1024  \n",
       "11        2048  \n",
       "12        4096  \n",
       "13        8192  \n",
       "14       16384  \n",
       "15       32768  \n",
       "16       65536  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable all CPU cores\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Read the file content\n",
    "def parse_to_datafame(file_path):\n",
    "  with open(file_path, \"r\") as file:\n",
    "      content = file.read()\n",
    "  # Define a regex pattern to extract the test case and its details\n",
    "  pattern = r\"\\s+cpu_time\\s+(?P<cpu_time>[\\d.]+)\\s+gpu_gb_in\\s+(?P<gpu_gb_in>[\\d.]+)\\s+gpu_gb_out\\s+(?P<gpu_gb_out>[\\d.]+)\\s+gpu_gb_total\\s+(?P<gpu_gb_total>[\\d.]+)\\s+gpu_between_atoms\\s+(?P<gpu_between_atoms>[\\d.]+)\\s+gpu_in_atoms\\s+(?P<gpu_in_atoms>[\\d.]+)\\s+gpu_time\\s+(?P<gpu_time>[\\d.]+)\\s+gpu_transfer_time\\s+(?P<gpu_transfer_time>[\\d.]+)\\s+gpu_walltime\\s+(?P<gpu_walltime>[\\d.]+)\\s+batch_size\\s+(?P<batch_size>[\\d.]+)\"\n",
    "\n",
    "  # Use re.finditer to extract all matches\n",
    "  matches = re.finditer(pattern, content)\n",
    "\n",
    "  # Create a list of dictionaries to store the extracted data\n",
    "  data = []\n",
    "  for match in matches:\n",
    "      data.append(match.groupdict())\n",
    "\n",
    "  # Convert the list of dictionaries into a pandas DataFrame\n",
    "  df = pd.DataFrame(data)\n",
    "\n",
    "# Convert numeric columns to appropriate data types\n",
    "  numeric_columns = [\n",
    "    'cpu_time', 'gpu_gb_in', 'gpu_gb_out', 'gpu_gb_total',\n",
    "    'gpu_between_atoms', 'gpu_in_atoms', 'gpu_time', 'gpu_transfer_time', \"batch_size\"\n",
    "  ]\n",
    "  # # Convert the numeric columns to float\n",
    "  df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric)\n",
    "\n",
    "  # Display the DataFrame\n",
    "  return df\n",
    "\n",
    "df = parse_to_datafame(f\"notes/capture/{option}/batchgpu.txt\")\n",
    "df.to_csv(f\"notes/data/{option}/batchgpu.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7817e0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "Architecture:             x86_64\n",
      "  CPU op-mode(s):         32-bit, 64-bit\n",
      "  Address sizes:          46 bits physical, 57 bits virtual\n",
      "  Byte Order:             Little Endian\n",
      "CPU(s):                   128\n",
      "  On-line CPU(s) list:    0-127\n",
      "Vendor ID:                GenuineIntel\n",
      "  Model name:             Intel(R) Xeon(R) Gold 6448Y\n",
      "    CPU family:           6\n",
      "    Model:                143\n",
      "    Thread(s) per core:   2\n",
      "    Core(s) per socket:   32\n",
      "    Socket(s):            2\n",
      "    Stepping:             8\n",
      "    CPU max MHz:          4100.0000\n",
      "    CPU min MHz:          800.0000\n",
      "    BogoMIPS:             4200.00\n",
      "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n",
      "                          ca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 s\n",
      "                          s ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc \n",
      "                          art arch_perfmon pebs bts rep_good nopl xtopology nons\n",
      "                          top_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq \n",
      "                          dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma c\n",
      "                          x16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popc\n",
      "                          nt tsc_deadline_timer aes xsave avx f16c rdrand lahf_l\n",
      "                          m abm 3dnowprefetch cpuid_fault epb cat_l3 cat_l2 cdp_\n",
      "                          l3 cdp_l2 ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_s\n",
      "                          hadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust\n",
      "                           bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f av\n",
      "                          x512dq rdseed adx smap avx512ifma clflushopt clwb inte\n",
      "                          l_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec\n",
      "                           xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cq\n",
      "                          m_mbm_local split_lock_detect user_shstk avx_vnni avx5\n",
      "                          12_bf16 wbnoinvd dtherm ida arat pln pts hfi vnmi avx5\n",
      "                          12vbmi umip pku ospke waitpkg avx512_vbmi2 gfni vaes v\n",
      "                          pclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcnt\n",
      "                          dq la57 rdpid bus_lock_detect cldemote movdiri movdir6\n",
      "                          4b enqcmd fsrm md_clear serialize tsxldtrk pconfig arc\n",
      "                          h_lbr ibt amx_bf16 avx512_fp16 amx_tile amx_int8 flush\n",
      "                          _l1d arch_capabilities\n",
      "Virtualization features:  \n",
      "  Virtualization:         VT-x\n",
      "Caches (sum of all):      \n",
      "  L1d:                    3 MiB (64 instances)\n",
      "  L1i:                    2 MiB (64 instances)\n",
      "  L2:                     128 MiB (64 instances)\n",
      "  L3:                     120 MiB (2 instances)\n",
      "NUMA:                     \n",
      "  NUMA node(s):           2\n",
      "  NUMA node0 CPU(s):      0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38\n",
      "                          ,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74\n",
      "                          ,76,78,80,82,84,86,88,90,92,94,96,98,100,102,104,106,1\n",
      "                          08,110,112,114,116,118,120,122,124,126\n",
      "  NUMA node1 CPU(s):      1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39\n",
      "                          ,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75\n",
      "                          ,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,1\n",
      "                          09,111,113,115,117,119,121,123,125,127\n",
      "Vulnerabilities:          \n",
      "  Gather data sampling:   Not affected\n",
      "  Itlb multihit:          Not affected\n",
      "  L1tf:                   Not affected\n",
      "  Mds:                    Not affected\n",
      "  Meltdown:               Not affected\n",
      "  Mmio stale data:        Not affected\n",
      "  Reg file data sampling: Not affected\n",
      "  Retbleed:               Not affected\n",
      "  Spec rstack overflow:   Not affected\n",
      "  Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prct\n",
      "                          l\n",
      "  Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointe\n",
      "                          r sanitization\n",
      "  Spectre v2:             Mitigation; Enhanced / Automatic IBRS; IBPB conditiona\n",
      "                          l; RSB filling; PBRSB-eIBRS SW sequence; BHI BHI_DIS_S\n",
      "  Srbds:                  Not affected\n",
      "  Tsx async abort:        Not affected\n",
      "Sun May 25 16:38:28 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:68:00.0 Off |                    0 |\n",
      "| N/A   42C    P0             71W /  700W |       1MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nproc\n",
    "!lscpu\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efd506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
